# GENIAC Topic 1 LLM Evaluation Baseline Configuration
# Sanden Repair System - Domestic LLM Benchmark
# Version: 1.0.0
# Date: 2025-09-22

# =============================================
# MODEL CONFIGURATION & VERSION PINNING
# =============================================

model:
  name: "Claude 3.5 Sonnet"
  provider: "Anthropic"
  version: "claude-3-5-sonnet-20241022"
  context_window: 200000
  temperature: 0.6
  top_p: 0.9
  max_tokens: 4096
  seed: [1, 11, 111]  # For reproducibility - 3 seed dispersion testing

# =============================================
# ENVIRONMENT & DEPENDENCIES
# =============================================

environment:
  node_version: "18.17.0"
  npm_version: "9.6.7"
  os: "Amazon Linux 2"
  architecture: "x86_64"

dependencies:
  "@mastra/core": "^0.1.0"
  "@mastra/mcp": "^0.1.0"
  "zod": "^3.22.4"
  "langfuse": "^1.0.0"
  "zapier-mcp": "^1.0.0"

# =============================================
# INFRASTRUCTURE CONFIGURATION
# =============================================

infrastructure:
  deployment: "AWS EC2"
  instance_type: "t3.medium"
  region: "ap-northeast-1"
  memory: "4GB"
  cpu: "2 vCPU"

# =============================================
# TOOL CONFIGURATION
# =============================================

tools:
  active_tools:
    - id: "lookupCustomerFromDatabase"
      source: "src/mastra/tools/sanden/orchestrator-tools.ts"
      description: "Customer database lookup by ID, name, email, phone"
      timeout: 30000
      retries: 3

    - id: "directRepairHistory"
      source: "src/mastra/agents/sanden/customer-identification.ts"
      description: "Direct repair history retrieval without delegation"
      timeout: 30000
      retries: 3

  available_but_unused_tools: []

# =============================================
# AGENT CONFIGURATION
# =============================================

agents:
  customer_identification:
    id: "customer-identification"
    prompt_source: "Langfuse"
    prompt_version: "latest"
    tools: ["lookupCustomerFromDatabase", "directRepairHistory"]
    temperature: 0.6
    max_iterations: 5

# =============================================
# SCOPE & LIMITATIONS
# =============================================

scope:
  target_agents: ["customer-identification", "repair-scheduling (delegation)"]
  target_behaviors: ["ツール呼び出しの選定と引数妥当性", "ワークフロー完了", "安全性と敬語"]
  excluded_behaviors: ["生成的クリエイティブ応答", "長文要約", "非業務ドメイン"]

# =============================================
# EXECUTION CONFIGURATION
# =============================================

execution:
  runner: "Custom Node.js runner"
  streaming: true
  retry_policy: "none"
  logging: ["Langfuse logs", "Tool call logs", "Stage-wise timing"]

# =============================================
# COMPARISON TARGETS
# =============================================

comparison_targets:
  domestic_llms: ["Karakuri LM", "Tsuzumi", "Plamo"]
  execution_conditions: "Same parameters and tool specifications"

# =============================================
# DATASET CONFIGURATION
# =============================================

dataset:
  current:
    name: "customer-identification-20"
    format: "JavaScript Array"
    location: "test-all-prompts.js"
    size: 20
    intents: 12
    coverage: "Customer identification and routing scenarios"

  target:
    name: "geniac-complete-120"
    format: "JSONL"
    location: "test-data/geniac-dataset.jsonl"
    size: 120
    intents: 12
    variants_per_intent: 10
    coverage: "Full GENIAC Topic 1 requirements"

# =============================================
# EVALUATION METRICS
# =============================================

evaluation:
  quality_metrics:
    - name: "ツール正確性"
      weight: 0.40
      scale: "1-5"
      description: "Correct tool selection and argument validity"

    - name: "ワークフロー完了"
      weight: 0.30
      scale: "1-5"
      description: "Successful completion of customer service workflow"

    - name: "コミュニケーション"
      weight: 0.15
      scale: "1-5"
      description: "Professional communication and Japanese business etiquette"

    - name: "安全"
      weight: 0.10
      scale: "1-5"
      description: "PII protection and appropriate refusal mechanisms"

    - name: "取得適合"
      weight: 0.05
      scale: "1-5"
      description: "Appropriateness of retrieved information and data access"

  operations_metrics:
    - name: "p50レイテンシ"
      unit: "ms"
      target: "< 2000"
      description: "Median response time across all requests"

    - name: "p95レイテンシ"
      unit: "ms"
      target: "< 5000"
      description: "95th percentile response time"

    - name: "p99レイテンシ"
      unit: "ms"
      target: "< 10000"
      description: "99th percentile response time"

    - name: "エラーレート"
      unit: "%"
      target: "< 1"
      description: "Percentage of failed requests"

    - name: "1セッション当たりコスト"
      unit: "USD"
      target: "< 0.002"
      description: "Cost per conversation session"

    - name: "スループット"
      unit: "requests/sec"
      target: "> 2"
      description: "Sustained request throughput"

    - name: "3シード分散"
      unit: "variability"
      target: "< 10%"
      description: "Response variability across 3 different random seeds"

# =============================================
# ACCEPTANCE CRITERIA (SLOs)
# =============================================

acceptance_criteria:
  quality: "基準線と同等以上"
  safety: "基準線と同等以上"
  operations: "目標SLO以内"

# =============================================
# REPRODUCIBILITY ARTIFACTS
# =============================================

reproducibility:
  git_commit: "8e34115"  # Current commit hash
  git_branch: "domesticLLMtesting"
  git_repository: "https://github.com/vottia-jp/maestra-demo.git"

  container_image: "maestra-demo:domestic-llm-testing-v1.0.0"
  dockerfile: "Dockerfile.benchmark"

  test_data_hash: "SHA256_PLACEHOLDER"
  prompt_hash: "SHA256_PLACEHOLDER"

# =============================================
# TEST EXECUTION CONFIGURATION
# =============================================

execution:
  concurrency: 1
  timeout_per_test: 60000  # 60 seconds
  retries_per_test: 3
  delay_between_tests: 1000  # 1 second

  environment_variables:
    LANGFUSE_PUBLIC_KEY: "${LANGFUSE_PUBLIC_KEY}"
    LANGFUSE_SECRET_KEY: "${LANGFUSE_SECRET_KEY}"
    ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"

  logging:
    level: "INFO"
    format: "JSON"
    destination: "test-results/"
    metrics_destination: "test-reports/"

# =============================================
# COMPLIANCE & VALIDATION
# =============================================

compliance:
  geniac_topic: 1
  benchmark_standard: "GENIAC LLM Evaluation Framework v1.0"
  validation_date: "2025-09-22"
  validator: "Claude 3.5 Sonnet Baseline"

  audit_trail:
    - "Initial 20 test cases validated: 2025-09-22"
    - "Quality metrics established: 2025-09-22"
    - "Performance baseline captured: 2025-09-22"
    - "GENIAC compliance gaps identified: 2025-09-22"

# =============================================
# FUTURE EXPANSION ROADMAP
# =============================================

roadmap:
  phase_2:
    - Expand dataset to 120 test cases
    - Add multi-agent workflow testing
    - Implement safety evaluation framework
    - Add cross-model comparison capabilities

  phase_3:
    - Production deployment validation
    - Real-world performance monitoring
    - Continuous evaluation pipeline
    - Multi-language support (English/Korean)
